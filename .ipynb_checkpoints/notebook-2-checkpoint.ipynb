{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8e7c8928-62c9-0abb-781e-edb0eb38ecf3",
    "_uuid": "7946b9352dc04693780022204ef0eddc1cc847d5"
   },
   "source": [
    "### Kaggle Invasive Species Monitoring: Get 0.97 accuracy with minimal effort.\n",
    "Finetune VGG16 top layers with Keras as described by Francois Chollet here:\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f32bc8ff-1fba-1bec-5c28-ad76fa6302d3",
    "_uuid": "f53e875e9bdac4b2a514d35f5ddc7efe15c04d09"
   },
   "source": [
    "*chmaxx _ 26.5.17*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "87c4c624-0670-cbf6-9282-d94bac780c4f",
    "_uuid": "bde2c9cdde4b7b83b453e4f067aae12d554e1585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? \n",
      "Nothing done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from tqdm import tqdm_notebook\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_rows = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "97873997-b4a4-b84f-72dd-7f316a107459",
    "_uuid": "0590257bdd1bae0f6b9fe1b2fcbe5d5d95b8ced3"
   },
   "source": [
    "Import Labels and check distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "32f2db0d-ff38-c04d-c6bd-6c0853d56bc5",
    "_uuid": "e7971a07d5292a105548fa39666e09048542653f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1448\n",
       "0     847\n",
       "Name: invasive, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"train_labels.csv\"\n",
    "df = pd.read_csv(file, sep=\",\", error_bad_lines= True)\n",
    "df.invasive.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b6d8979b-0339-8bee-1393-22ca3f6f4f47",
    "_uuid": "60835c6040ceb50d2e2a6eda03c932d5c4fe6880"
   },
   "source": [
    "Separate Images according to their labels. Move them to either class folder **false/** or **true/**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4fda719e-f6fb-7dee-4688-f12e51b42655",
    "_uuid": "a5efdcf29916dca93ac9110349581d2427e810f9"
   },
   "source": [
    "After separating the images into two classes I manually moved 400 images to the validation folder (again with separate folders for the two classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4aea5aea-7ed1-89d7-6787-1aa79f288df4",
    "_uuid": "96adb3f0717169b97f7e284350e5bac1014627be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '_train'\n",
      "/Users/pagidoju/Documents/Git_repositories/MachineLearningCapstone\n",
      "mv: rename 1.jpg to false/: No such file or directory\n",
      "mv: rename 2.jpg to false/: No such file or directory\n",
      "mv: rename 3.jpg to true/: No such file or directory\n",
      "mv: rename 4.jpg to false/: No such file or directory\n",
      "mv: rename 5.jpg to true/: No such file or directory\n",
      "mv: rename 6.jpg to false/: No such file or directory\n",
      "mv: rename 7.jpg to true/: No such file or directory\n",
      "mv: rename 8.jpg to true/: No such file or directory\n",
      "mv: rename 9.jpg to false/: No such file or directory\n",
      "mv: rename 10.jpg to false/: No such file or directory\n",
      "mv: rename 11.jpg to true/: No such file or directory\n",
      "mv: rename 12.jpg to true/: No such file or directory\n",
      "mv: rename 13.jpg to true/: No such file or directory\n",
      "mv: rename 14.jpg to false/: No such file or directory\n",
      "mv: rename 15.jpg to false/: No such file or directory\n",
      "mv: rename 16.jpg to false/: No such file or directory\n",
      "mv: rename 17.jpg to false/: No such file or directory\n",
      "mv: rename 18.jpg to true/: No such file or directory\n",
      "mv: rename 19.jpg to true/: No such file or directory\n",
      "mv: rename 20.jpg to true/: No such file or directory\n",
      "mv: rename 21.jpg to true/: No such file or directory\n",
      "mv: rename 22.jpg to false/: No such file or directory\n",
      "mv: rename 23.jpg to true/: No such file or directory\n",
      "mv: rename 24.jpg to false/: No such file or directory\n",
      "mv: rename 25.jpg to true/: No such file or directory\n",
      "mv: rename 26.jpg to false/: No such file or directory\n",
      "mv: rename 27.jpg to true/: No such file or directory\n",
      "mv: rename 28.jpg to true/: No such file or directory\n",
      "mv: rename 29.jpg to true/: No such file or directory\n",
      "mv: rename 30.jpg to true/: No such file or directory\n",
      "mv: rename 31.jpg to false/: No such file or directory\n",
      "mv: rename 32.jpg to true/: No such file or directory\n",
      "mv: rename 33.jpg to true/: No such file or directory\n",
      "mv: rename 34.jpg to true/: No such file or directory\n",
      "mv: rename 35.jpg to true/: No such file or directory\n",
      "mv: rename 36.jpg to true/: No such file or directory\n",
      "mv: rename 37.jpg to true/: No such file or directory\n",
      "mv: rename 38.jpg to false/: No such file or directory\n",
      "mv: rename 39.jpg to true/: No such file or directory\n",
      "mv: rename 40.jpg to true/: No such file or directory\n",
      "mv: rename 41.jpg to false/: No such file or directory\n",
      "mv: rename 42.jpg to true/: No such file or directory\n",
      "mv: rename 43.jpg to true/: No such file or directory\n",
      "mv: rename 44.jpg to true/: No such file or directory\n",
      "mv: rename 45.jpg to false/: No such file or directory\n",
      "mv: rename 46.jpg to true/: No such file or directory\n",
      "mv: rename 47.jpg to true/: No such file or directory\n",
      "mv: rename 48.jpg to true/: No such file or directory\n",
      "mv: rename 49.jpg to false/: No such file or directory\n",
      "mv: rename 50.jpg to false/: No such file or directory\n",
      "mv: rename 51.jpg to false/: No such file or directory\n",
      "mv: rename 52.jpg to true/: No such file or directory\n",
      "mv: rename 53.jpg to false/: No such file or directory\n",
      "mv: rename 54.jpg to false/: No such file or directory\n",
      "mv: rename 55.jpg to true/: No such file or directory\n",
      "mv: rename 56.jpg to true/: No such file or directory\n",
      "mv: rename 57.jpg to true/: No such file or directory\n",
      "mv: rename 58.jpg to true/: No such file or directory\n",
      "mv: rename 59.jpg to true/: No such file or directory\n",
      "mv: rename 60.jpg to true/: No such file or directory\n",
      "mv: rename 61.jpg to true/: No such file or directory\n",
      "mv: rename 62.jpg to true/: No such file or directory\n",
      "mv: rename 63.jpg to true/: No such file or directory\n",
      "mv: rename 64.jpg to true/: No such file or directory\n",
      "mv: rename 65.jpg to false/: No such file or directory\n",
      "mv: rename 66.jpg to true/: No such file or directory\n",
      "mv: rename 67.jpg to false/: No such file or directory\n",
      "mv: rename 68.jpg to true/: No such file or directory\n",
      "mv: rename 69.jpg to false/: No such file or directory\n",
      "mv: rename 70.jpg to false/: No such file or directory\n",
      "mv: rename 71.jpg to true/: No such file or directory\n",
      "mv: rename 72.jpg to true/: No such file or directory\n",
      "mv: rename 73.jpg to true/: No such file or directory\n",
      "mv: rename 74.jpg to true/: No such file or directory\n",
      "mv: rename 75.jpg to false/: No such file or directory\n",
      "mv: rename 76.jpg to true/: No such file or directory\n",
      "mv: rename 77.jpg to true/: No such file or directory\n",
      "mv: rename 78.jpg to false/: No such file or directory\n",
      "mv: rename 79.jpg to true/: No such file or directory\n",
      "mv: rename 80.jpg to true/: No such file or directory\n",
      "mv: rename 81.jpg to true/: No such file or directory\n",
      "mv: rename 82.jpg to true/: No such file or directory\n",
      "mv: rename 83.jpg to true/: No such file or directory\n",
      "mv: rename 84.jpg to true/: No such file or directory\n",
      "mv: rename 85.jpg to false/: No such file or directory\n",
      "mv: rename 86.jpg to true/: No such file or directory\n",
      "mv: rename 87.jpg to true/: No such file or directory\n",
      "mv: rename 88.jpg to false/: No such file or directory\n",
      "mv: rename 89.jpg to false/: No such file or directory\n",
      "mv: rename 90.jpg to true/: No such file or directory\n",
      "mv: rename 91.jpg to true/: No such file or directory\n",
      "mv: rename 92.jpg to false/: No such file or directory\n",
      "mv: rename 93.jpg to false/: No such file or directory\n",
      "mv: rename 94.jpg to true/: No such file or directory\n",
      "mv: rename 95.jpg to false/: No such file or directory\n",
      "mv: rename 96.jpg to true/: No such file or directory\n",
      "mv: rename 97.jpg to true/: No such file or directory\n",
      "mv: rename 98.jpg to true/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%cd _train\n",
    "names = df.name\n",
    "labels = df.invasive\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    iname = str(names[idx]) + \".jpg\"\n",
    "    if (label == 0):\n",
    "        !mv $iname false/\n",
    "    elif (label == 1):\n",
    "        !mv $iname true/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f92cddf-7e1a-0c6b-b6ea-891594631fc7",
    "_uuid": "e3fd5d1e767579e4e8c988feaf5188ab13b541af",
    "collapsed": true
   },
   "source": [
    "### Build the CNN\n",
    "We use the Keras VGG16 application with weights but without top. We add an untrained DNN on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "62f77dcc-aae3-4ad5-b990-bb3ae70f983b",
    "_uuid": "10efbe86b1b83876b67a09282492df008f1a21e2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "x = vgg16.get_layer('block5_conv3').output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_final = Model(inputs=vgg16.input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "535d287a-e050-69fd-dd04-7ecbd183e131",
    "_uuid": "f673f4873304a186bad9b8270cae1e73bbadae0a"
   },
   "source": [
    "Freeze all VGG layers and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0f68a5aa-40f9-d6f4-8175-8e830008cfd6",
    "_uuid": "0c656a7896ff082e552aaece9a2e20170f15fad2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_final.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7542214f-44a6-46ce-c902-4b391c791d5e",
    "_uuid": "e096be846839bfb32af614a48b1bbb186253bfc5"
   },
   "source": [
    "### Setup the Datagenerator \n",
    "The interesting point here is, **that we seem to be able to feed any image size to VGG16 and not only 224x224px**. This is particularly meant to improve accuracy for hard to detect images when invasive plants appear only very small in the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5fa89f4d-5cc2-9bed-ceb6-5bb406bde105",
    "_uuid": "63ead62bee75c7f15f0611d4ca46a416d4480bd9"
   },
   "source": [
    "**Hat tip and thanks to Crequena** for that recommendation. See this thread: https://www.kaggle.com/fujisan/use-keras-pre-trained-vgg16-acc-98/comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7435eacc-1bba-e3ab-010e-377ffcdb9857",
    "_uuid": "9291879456f33ee0b922d2b5508751ebea657fb9"
   },
   "source": [
    "I first trained with a small size of 300/225px until early stopping. Than I trained again with 600/450px until early stopping. Feel free to try with even bigger sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7396ea9f-530e-e36b-a8d1-a40796294d83",
    "_uuid": "7e11a1f25028482cdea13e364ecbc54ced4d50ba",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You need to have these three folders each with two subfolders for the two classes.\n",
    "train_data_dir = \"D:/KI/01_keras/_kaggle/_invasiveplants/_train\"\n",
    "validation_data_dir = \"D:/KI/01_keras/_kaggle/_invasiveplants/_validate\"\n",
    "test_data_dir = \"D:/KI/01_keras/_kaggle/_invasiveplants/_test\"\n",
    "\n",
    "# 600/450 _ 500/375 _ 400/300 _ 300/225\n",
    "\n",
    "img_width = 600  # Change image size for training here\n",
    "img_height = 450 # Change image size for training here\n",
    "\n",
    "batch_size = 5 # i achieved good and fast results with this small minibatch size for training\n",
    "batch_size_val = 400 # if Tensorflow throws a memory error while validating at end of epoch, decrease validation batch size her\n",
    "\n",
    "# set data augmentation parameters here\n",
    "datagen = ImageDataGenerator(rescale=1., \n",
    "    featurewise_center=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=.1,\n",
    "    height_shift_range=.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"reflect\")\n",
    "\n",
    "# normalization neccessary for correct image input to VGG16\n",
    "datagen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)\n",
    "\n",
    "# no data augmentation for validation and test set\n",
    "validgen = ImageDataGenerator(rescale=1., featurewise_center=True)\n",
    "validgen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)\n",
    "\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True, \n",
    "        #save_to_dir=\"_augmented_images/\", \n",
    "        #save_prefix=\"aug_\"\n",
    "        )\n",
    "\n",
    "val_gen = validgen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True)\n",
    "\n",
    "test_gen = validgen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=1,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=False)\n",
    "\n",
    "train_samples = len(train_gen.filenames)\n",
    "validation_samples = len(val_gen.filenames)\n",
    "test_samples = len(test_gen.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8ad1c88e-b3d8-2fc1-2e88-0fdd6d366fc1",
    "_uuid": "b913b1ba0727ca52e12d6050022015ed4efd0519",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "# \"_tf_logs\" is my Tensorboard folder. Change this to your setup if you want to use TB\n",
    "logdir = \"_tf_logs/\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "tb = TensorBoard(log_dir=logdir)\n",
    "\n",
    "epochs=10\n",
    "\n",
    "# I stopped training automagically with EarlyStopping after 3 consecutive epochs without improvement\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "model_final.fit_generator(train_gen, epochs=epochs, \n",
    "                          steps_per_epoch=int(train_samples/batch_size), \n",
    "                          validation_data=val_gen, \n",
    "                          validation_steps=batch_size_val, \n",
    "                          verbose=0, callbacks=[early_stopping, tb, TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e1436d45-0681-c1ec-a490-2a361d8ce16c",
    "_uuid": "d0aaf36336f72d592481291e1565f8521ae41733"
   },
   "source": [
    "After doing two rounds of training until early stopping (one with a small image size, one with a larger size) we do a second round of training that now includes the last convolutional block of the VGG16, that until now was frozen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4bdafad6-acfc-2807-014e-66cf690acd77",
    "_uuid": "3dd7939b25c19a075e1aa731983c782243f8553d"
   },
   "source": [
    "First we printout all layers. Than we freeze all layers up to the last conv block and compile again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d1f2acc7-b284-acf2-4389-bba96be8a57e",
    "_uuid": "c629d460b423217fd4f600fb727ea5fa65bc44a3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model_final.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "for layer in model_final.layers[:15]:\n",
    "   layer.trainable = False\n",
    "for layer in model_final.layers[15:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9f781510-b59f-a635-7036-ccd591ea8085",
    "_uuid": "a230fcecda241f43eebd4b4ba778a2c368873eaf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.compile(optimizer=SGD(lr=0.0001, momentum=0.9, nesterov=True),  loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11badc01-bb30-0a11-0783-17d78d3974b2",
    "_uuid": "624d026e246aa301f6c91afb77de65a2f9886dd1"
   },
   "source": [
    "Again I did two rounds of training in this second step: First round with a small image size until early stopping, than a second round with the large image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e4378335-15c7-6c83-3a81-7fc260a90729",
    "_uuid": "826a7457742cf193980ae4faf52f63a2aff33387",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "# \"_tf_logs\" is my Tensorboard folder. Change this to your setup if you want to use TB\n",
    "logdir = \"_tf_logs/\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "tb = TensorBoard(log_dir=logdir)\n",
    "\n",
    "epochs=50\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "model_final.fit_generator(train_gen, epochs=epochs, \n",
    "                          steps_per_epoch=int(train_samples/batch_size), \n",
    "                          validation_data=val_gen, \n",
    "                          validation_steps=int(validation_samples/batch_size), \n",
    "                          verbose=0, callbacks=[early_stopping, tb, TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b049cfbc-2648-f8b6-afe2-ce235f6991bf",
    "_uuid": "fdd94e8d16f31d25cb6f651f1fa6ab6eee4e7aa4"
   },
   "source": [
    "Make predictions for test images and save as submission CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3984a18b-eda4-aa5d-f5da-b3c86dd1a2ec",
    "_uuid": "6c1de6ad2a1960edaf716d3b5334769bed7a3370",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model_final.predict_generator(test_gen, 1531)\n",
    "preds_rounded = []\n",
    "\n",
    "for pred in preds:\n",
    "    if (pred > .5):\n",
    "        preds_rounded.append(\"1\")\n",
    "    else:\n",
    "        preds_rounded.append(\"0\")\n",
    "\n",
    "preds_filenames = [int(x.replace(\"test\\\\\", \"\").replace(\".jpg\", \"\")) for x in test_gen.filenames]   \n",
    "\n",
    "data = (list(zip(preds_filenames, preds_rounded)))\n",
    "\n",
    "df_result = pd.DataFrame(data, columns=[\"name\", \"invasive\"])\n",
    "df_result = df_result.sort_values(\"name\")\n",
    "df_result.index = df_result[\"name\"]\n",
    "df_result = df_result.drop([\"name\"], axis=1)\n",
    "\n",
    "df_result.to_csv(\"_kaggle/_invasiveplants/submission_03.csv\", encoding=\"utf8\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b385a71a-70ec-4922-04ef-c2767c8f4a30",
    "_uuid": "2fb25f5ab71c49ea6c3432fee784f3d5de1fcad4",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
